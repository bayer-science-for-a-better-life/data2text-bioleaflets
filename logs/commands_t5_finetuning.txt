 1106  ls boxscore-data/gen_model/cc/
 1107  MODEL_PATH=$BASE/gen_model/cc/roto_stage1_acc_72.5621_ppl_2.8978_e5.pt 
 1108  echo $MODEL_PATH 
 1109  python translate.py -model $MODEL_PATH -src1 $BASE/rotowire/inf_src_valid.txt -output $BASE/gen/roto_stage1_$IDENTIFIER-beam5_gens.txt -batch_size 10 -max_length 80 -gpu $GPUID -min_length 35 -stage1
 1110  GPUID=0
 1111  python translate.py -model $MODEL_PATH -src1 $BASE/rotowire/inf_src_valid.txt -output $BASE/gen/roto_stage1_$IDENTIFIER-beam5_gens.txt -batch_size 10 -max_length 80 -gpu $GPUID -min_length 35 -stage1
 1112  find . -name 'roto_stage1_cc-beam5_gens.txt'
 1113  find . -name '*beam5_gens*'
 1114  python scripts/create_content_plan_from_index.py $BASE/rotowire/inf_src_valid.txt $BASE/gen/roto_stage1_$IDENTIFIER-beam5_gens.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt  $BASE/gen/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt
 1115  echo "Try create file manually"
 1116  echo $BASE
 1117  ls /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/gen_model/cc/
 1118  touch /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/gen/roto_stage1_cc-beam5_gens.txt
 1119  ls /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/gen_model/echo $BASE
 1120  echo $BASE
 1121  echo $IDENTIFIER 
 1122  echo "During inference, we first generate the content plan, but now without TYPO"
 1123  echo $MODEL_PATH
 1124  python translate.py -model $MODEL_PATH -src1 $BASE/rotowire/inf_src_valid.txt -output $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt -batch_size 10 -max_length 80 -gpu $GPUID -min_length 35 -stage1
 1125  ls boxscore-data/gen_model/cc/
 1126  # $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt
 1127  echo "This script generates the content plan with records from input of content plan with indices"
 1128  python scripts/create_content_plan_from_index.py $BASE/rotowire/inf_src_valid.txt $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt $BASE/gen_model/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt
 1129  ls boxscore-data/gen_model/
 1130  echo "Problem-'/home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/transform_gen/roto_stage1_cc-beam5_gens.h5-tuples.txt'"
 1131  find . -name '*h5-tuples.txt'
 1132  python scripts/create_content_plan_from_index.py $BASE/rotowire/inf_src_valid.txt $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt  $BASE/gen_model/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt
 1133  cd nlg-ra/
 1134  ls
 1135  cd reproducibility/
 1136  ls
 1137  git status
 1138  cd data2text-plan-py/
 1139  ll
 1140  ls
 1141  cd ..
 1142  ls
 1143  mkdir test_data2text-plan-py
 1144  ls
 1145  cd test_data2text-plan-py/
 1146  ls
 1147  git clone https://github.com/ratishsp/data2text-plan-py.git
 1148  ll
 1149  cd data2text-plan-py/
 1150  ls
 1151  ll
 1152  rm -r .git/
 1153  y
 1154  ls
 1155  ll
 1156  conda env list
 1157  conda activate data2text_plan_py
 1158  ls
 1159  cp ~/s3raw/rotowire.tar.bz2 .
 1160  ls
 1161  tar -jxvf rotowire.tar.bz2
 1162  ls
 1163  mv rotowire rotowire_original_dataset
 1164  ls
 1165  cd rotowire_original_dataset/
 1166  ls
 1167  cd ..
 1168  ls
 1169  ls rotowire_original_dataset/
 1170  ls
 1171  ls scripts/
 1172  cd ~/nlg-ra/
 1173  git status
 1174  git add reproducibility/data2text-plan-py/
 1175  git status
 1176  git reset HEAD -- reproducibility/data2text-plan-py/rotowire-dataset-4-pudupully.zip
 1177  git status
 1178  git commit -m "Data2text by Puduppully, status - training model from paper on the example data - RotoWire"
 1179  git status
 1180  git push
 1181  git status
 1182  git reset --soft HEAD~1
 1183  git status
 1184  git reset HEAD -- .
 1185  git status
 1186  cd reproducibility/data2text-plan-py/
 1187  ls
 1188  ls boxscore-data/gen_model/cc/roto_stage
 1189  ls boxscore-data/gen_model/cc/
 1190  ls
 1191  cd ..
 1192  ls
 1193  cd test_data2text-plan-py/
 1194  ls
 1195  cd data2text-plan-py/
 1196  ls
 1197  ls scripts/
 1198  cd scripts/
 1199  ls
 1200  python create_dataset.py 
 1201  cd ..
 1202  ls
 1203  cp text2num.py scripts/text2num.py
 1204  cd scripts/
 1205  ls
 1206  cd ..
 1207  ls
 1208  ls rotowire
 1209  ls rotowire_original_dataset/
 1210  cd scripts/
 1211  python create_dataset.py
 1212  ls
 1213  cd ..
 1214  ls
 1215  cp scripts/create_dataset.py create_dataset.py
 1216  ls
 1217  python create_dataset.py 
 1218  ls
 1219  mkdir rotowire
 1220  ls
 1221  touch roto_train-beam5_gens.h5-tuples.txt
 1222  ls
 1223  ls -lh
 1224  rm -r roto_train-beam5_gens.h5-tuples.txt
 1225  ls
 1226  ls -lh
 1227  cp ~/s3raw/roto_train-beam5_gens.h5-tuples.txt .
 1228  ls
 1229  ls -lh
 1230  ls
 1231  ls rotowire/
 1232  python create_dataset.py
 1233  ls
 1234  cp -r ~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/ ./drive-data-official
 1235  ls
 1236  cd drive-data-official/
 1237  ls
 1238  cd ..
 1239  ls
 1240  rm -r drive-data-official/
 1241  ls
 1242  cp -r ~/nlg-ra/reproducibility/data2text-plan-py/rotowire-dataset-4-pudupully.zip ./
 1243  ls
 1244  ls roto/
 1245  ls rotowire/
 1246  rmdir rotowire
 1247  ls
 1248  unzip rotowire-dataset-4-pudupully.zip
 1249  ls
 1250  mv rotowire drive_rotowire
 1251  ls
 1252  cd drive_rotowire/
 1253  ls
 1254  pwd
 1255  ls ..
 1256  ls
 1257  nvidia-smi
 1258  conda activate gpt-2
 1259  python
 1260  nvcc --version
 1261  conda env list
 1262  conda activate data2text_plan_py
 1263  nvidia-smi
 1264  python
 1265  nvcc --version
 1266  which python
 1267  cd nlg-ra/reproducibility/data2text-plan-py/
 1268  ls
 1269  which python
 1270  python
 1271  ls
 1272  BASE=~/boxscore-data
 1273  echo $BASE
 1274  BASE=~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data
 1275  IDENTIFIER=cc
 1276  GPUID=0
 1277  echo $GPUID
 1278  ls boxscore-data/gen_model/cc/
 1279  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 12 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1280  conda env list
 1281  conda activate data2text_plan_py
 1282  cd nlg-ra/reproducibility/data2text-plan-py/
 1283  ls
 1284  ls boxscore-data/rotowire/inter/
 1285  ls boxscore-data/rotowire/test/
 1286  conda env list
 1287  conda activate data2text_plan_py
 1288  cd nlg-ra/reproducibility/test_data2text-plan-py/data2text-plan-py/
 1289  ls
 1290  python create_dataset.py 
 1291  ls
 1292  mkdir boxscore-data
 1293  ls
 1294  cd boxscore-data/
 1295  ls
 1296  cd ..
 1297  ls
 1298  rmdir boxscore-data/
 1299  ls
 1300  mkdir rotowire
 1301  ls
 1302  cd rotowire
 1303  ls
 1304  cp ../rotowire_original_dataset/train.json .
 1305  ls
 1306  cd ..
 1307  ls
 1308  ls rotowire/
 1309  ls
 1310  ls rotowire-
 1311  ls rotowire/
 1312  python create_dataset.py
 1313  ls rotowire/
 1314  cd rotowire
 1315  ls
 1316  mkdir inter
 1317  ls
 1318  c d ..
 1319  cd ..
 1320  ls
 1321  ls rotowire/
 1322  python create_dataset.py
 1323  ls
 1324  ls rotowire/
 1325  ls inter/
 1326  ls inter
 1327  ls rotowire/inter/
 1328  ls rotowire/
 1329  ls rotowire/inter/
 1330  ls rotowire/
 1331  ls rotowire/inter/
 1332  conda env list
 1333  conda activate data2text_plan_py
 1334  cd nlg-ra/reproducibility/test_data2text-plan-py/data2text-plan-py/
 1335  ls
 1336  conda activate data2text_plan_py
 1337  cd nlg-ra/reproducibility/data2text-plan-py/
 1338  ls
 1339  echo "Actually generate text"
 1340  # BASE=~/boxscore-data
 1341  BASE=~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data
 1342  IDENTIFIER=cc
 1343  echo $BASE
 1344  echo $IDENTIFIER
 1345  GPUID=0
 1346  ehco $GPUID
 1347  echo $GPUID
 1348  ls boxscore-data/gen_model/cc/
 1349  # -output $BASE/gen/roto_stage1_$IDENTIFIER-beam5_gens.txt
 1350  echo "This script generates the content plan with records from input of content plan with indices"
 1351  cd boxscore-data/
 1352  ls
 1353  mkdir transform_gen
 1354  ls
 1355  cd ..
 1356  python scripts/create_content_plan_from_index.py $BASE/rotowire/inf_src_valid.txt $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt  $BASE/gen/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt
 1357  python scripts/create_content_plan_from_index.py $BASE/rotowire/inf_src_valid.txt $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt  $BASE/gen_model/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt
 1358  echo "Success"
 1359  echo "The accuracy of content plan in first stage can be evaluated using the following command"
 1360  cp ~/s3raw/roto-gold-val.h5-tuples.txt ~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/transform_gen/
 1361  ls boxscore-data/transform_gen/
 1362  python non_rg_metrics.py $BASE/transform_gen/roto-gold-val-beam5_gens.h5-tuples.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt
 1363  pip --version
 1364  which pip
 1365  pip install pyxDamerauLevenshtein
 1366  python non_rg_metrics.py $BASE/transform_gen/roto-gold-val-beam5_gens.h5-tuples.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt
 1367  ls boxscore-data/transform_gen/
 1368  python non_rg_metrics.py $BASE/transform_gen/roto-gold-val.h5-tuples.txt $BASE/transform_gen/roto_stage1_$IDENTIFIER-beam5_gens.h5-tuples.txt
 1369  echo "The output summary is generated using the command"
 1370  # MODEL_PATH2=<path to model2>
 1371  ls boxscore-data/gen_model/
 1372  ls boxscore-data/gen_model/cc/
 1373  MODEL_PATH2=~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/gen_model/cc/roto_stage2_acc_55.6671_ppl_8.3682_e6.pt
 1374  echo $MODEL_PATH2 
 1375  python translate.py -model $MODEL_PATH -model2 $MODEL_PATH2 -src1 $BASE/rotowire/inf_src_valid.txt -tgt1 $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt -src2 $BASE/gen_model/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt -output $BASE/gen_model/roto_stage2_$IDENTIFIER-beam5_gens.txt -batch_size 10 -max_length 850 -min_length 150 -gpu $GPUID
 1376  ls boxscore-data/gen_model/cc/
 1377  MODEL_PATH=~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/gen_model/cc/roto_stage1_acc_72.5621_ppl_2.8978_e5.pt
 1378  python translate.py -model $MODEL_PATH -model2 $MODEL_PATH2 -src1 $BASE/rotowire/inf_src_valid.txt -tgt1 $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt -src2 $BASE/gen_model/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt -output $BASE/gen_model/roto_stage2_$IDENTIFIER-beam5_gens.txt -batch_size 10 -max_length 850 -min_length 150 -gpu $GPUID
 1379  echo $MODEL_PATH
 1380  echo $MODEL_PATH2
 1381  echo $BASE
 1382  echo $IDENTIFIER
 1383  echo "-output $BASE/gen/roto_stage2_$IDENTIFIER-beam5_gens.txt"
 1384  echo $GPUID
 1385  ls boxscore-data/gen_model/
 1386   
 1387  ls
 1388  # python translate.py -model $MODEL_PATH -model2 $MODEL_PATH2 -src1 $BASE/rotowire/inf_src_valid.txt -tgt1 $BASE/gen_model/roto_stage1_$IDENTIFIER-beam5_gens.txt -src2 $BASE/gen_model/roto_stage1_inter_$IDENTIFIER-beam5_gens.txt -output $BASE/gen_model/roto_stage2_$IDENTIFIER-beam5_gens.txt -batch_size 10 -max_length 850 -min_length 150 -gpu $GPUID
 1389  echo "Metrics of RG, CS, CO are computed using the below commands."
 1390  # python data_utils.py -mode prep_gen_data -gen_fi $BASE/gen_model/roto_stage2_$IDENTIFIER-beam5_gens.txt -dict_pfx "roto-ie" -output_fi $BASE/transform_gen/roto_stage2_$IDENTIFIER-beam5_gens.h5 -input_path "/boxcore-json/rotowire"
 1391  ls
 1392  ls boxscore-data/
 1393  ls
 1394  conda env list
 1395  conda activate data2text_plan_py
 1396  cd nlg-ra/reproducibility/test_data2text-plan-py/data2text-plan-py/
 1397  ls
 1398  ls roto
 1399  ls rotowire
 1400  ls rotowire/inter/
 1401  ls drive_rotowire/
 1402  ls rotowire/
 1403  ls drive_rotowire/test/
 1404  ls drive_rotowire/
 1405  ls
 1406  ls rotowire.
 1407  ls rotowire/
 1408  ls drive_rotowire/
 1409  ls
 1410  ls rotowire
 1411  conda activate data2text_plan_py
 1412  cd nlg-ra/reproducibility/data2text-plan-py/
 1413  ls
 1414  ls boxscore-data/preprocess/
 1415  ls boxscore-data/transform_gen/
 1416  ls boxscore-data/rotowire/
 1417  ls boxscore-data/preprocess/
 1418  ls
 1419  ls boxscore-data/preprocess/
 1420  ls
 1421  ls boxscore-data/preprocess/
 1422  ls
 1423  ls boxscore-data/
 1424  ls boxscore-data/rotowire/
 1425  ls
 1426  ls boxscore-data/preprocess/
 1427  with open('rotowire/src_train.txt') as reader:
 1428  ls boxscore-data/rotowire/
 1429  ls
 1430  ls boxscore-data/
 1431  ls boxscore-data/rotowire/
 1432  ls
 1433  ls boxscore-data/rotowire/inter/
 1434  ls
 1435  mkdir bayer_dataset
 1436  ls
 1437  cd bayer_dataset/
 1438  ls
 1439  cp ~/nlg-ra/datasets/LeafletsDataset_section1_NER_outputs.dat .
 1440  ls
 1441  cp ~/nlg-ra/data_preparation/EMA_documents.py .
 1442  lks
 1443  ls
 1444  mkdir data_preparation
 1445  ls
 1446  mv EMA_documents.py data_preparation/
 1447  ls
 1448  ls data_preparation/
 1449  ls
 1450  conda env list
 1451  conda activate data2text_plan_py
 1452  ls
 1453  cd nlg-ra/reproducibility/test_data2text-plan-py/
 1454  cd data2text-plan-py/
 1455  ls
 1456  conda activate data2text_plan_py
 1457  ls
 1458  cd nlg-ra/reproducibility/data2text-plan-py/
 1459  ls
 1460  ls bayer_dataset/
 1461  ls
 1462  ls bayer_dataset/
 1463  mkdir inter
 1464  ls
 1465  ls bayer_dataset/
 1466  ls
 1467  rmdir inter
 1468  mkdir bayer_dataset/inter
 1469  ls
 1470  ls bayer_dataset/
 1471  ls
 1472  cd bayer_dataset/
 1473  ls
 1474  ls inter/
 1475  rm inter/train_content_plan.txt
 1476  ls inter/
 1477  ls
 1478  cd ..
 1479  ls
 1480  ls boxscore-data/
 1481  ls
 1482  cp -r boxscore-data/rotowire/ bayer_dataset/
 1483  cd bayer_dataset/
 1484  ls
 1485  ls rotowire/
 1486  ls
 1487  ls rotowire/inter/
 1488  ls
 1489  rm src_train.txt 
 1490  rm tgt_train.txt 
 1491  rm inter/train_content_plan.txt 
 1492  ls
 1493  rm tgt_train.txt 
 1494  ls
 1495  rm tgt_train.txt 
 1496  ls
 1497  l
 1498  ls
 1499  cat tgt_train.txt | head -n 10
 1500  cd ..
 1501  ls
 1502  cd boxscore-data/
 1503  ls
 1504  cd preprocess/
 1505  ls
 1506  mkdir tryouts
 1507  cd tryouts/
 1508  ls
 1509  wget https://bit.ly/pandora_profiles_15042020_x
 1510  ls
 1511  wget https://bit.ly/pandora_comments_15042020_x
 1512  wget https://bit.ly/pandora_baseline_30042020
 1513  ls
 1514  ll
 1515  unzip pandora_comments_15042020_x
 1516  ls
 1517  unzip pandora_profiles_15042020_x
 1518  ls
 1519  ll
 1520  cp ~/nlg-ra/gpt-2.ipynb .
 1521  ls
 1522  mkdir models
 1523  ls
 1524  mv ~/s3raw/Fine-tuning-new.ipynb .
 1525  ll
 1526  conda activate gpt-2
 1527  conda env list
 1528  ls
 1529  mv ~/s3raw/prepare-data.ipynb .
 1530  ls
 1531  pip install markdown
 1532  ls
 1533  mv all_comments_since_2015.csv all_comments_since_2015_ORIGINAL.csv
 1534  ls
 1535  mv all_comments_since_2015_updated.csv all_comments_since_2015.csv
 1536  ls
 1537  zip -r open_model_final.zip GPT2_10epoch_500k_openness95_4.pkl
 1538  ls
 1539  conda list
 1540  cd nlg-ra
 1541  git status
 1542  cd reproducibility/data2text-plan-py/
 1543  ls
 1544  echo "git ignore all .zip"
 1545  cd boxscore-data/
 1546  ls
 1547  ls gen_model/
 1548  ls gen_model/cc/
 1549  echo "git ignore all .pt"
 1550  ls gen_model/cc/
 1551  ls preprocess/
 1552  ll preprocess/
 1553  ls rotowire/
 1554  ls transform_gen/
 1555  cd ..
 1556  ls
 1557  ls bayer_dataset/
 1558  echo "git ignore all .dat files"
 1559  ls
 1560  cd ../..
 1561  ll
 1562  vim .gitignore
 1563  ls
 1564  vim .gitignore
 1565  git status
 1566  git add .gitignore
 1567  git status
 1568  git commit -m "Update .gitignore file to avoid tracking big-size files"
 1569  git push
 1570  git status
 1571  git add reproducibility/data2text-plan-py/
 1572  git status
 1573  git commit -m "Add data2text-plan project"
 1574  git status
 1575  git push
 1576  ls -sh ~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/
 1577  ls -sh ~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/rotowire/
 1578  git status
 1579  git reset --soft HEAD~1
 1580  git status
 1581  git --version
 1582  git reset
 1583  git status
 1584  vim .gitignore
 1585  git add .gitignore
 1586  git commit -m "Update gitignore file"
 1587  git add reproducibility/data2text-plan-py/
 1588  git status
 1589  git commit -m "Add the data2text-plain project"
 1590  git push
 1591  git status
 1592  ls reproducibility/test_data2text-plan-py/data2text-plan-py/rotowire
 1593  vim .gitignore
 1594  git add .gitignore
 1595  git commit -m "Update gitignore file"
 1596  git add reproducibility/test_data2text-plan-py/
 1597  git status
 1598  git reset 
 1599  git status
 1600  vim .gitignore
 1601  git add .gitignore
 1602  git status
 1603  git commit -m "Update gitignore file"
 1604  git add reproducibility/test_data2text-plan-py/
 1605  git status
 1606  git commit -m "Add a duplicate project - test_data2text_plain- for test purposes"
 1607  git push
 1608  ls
 1609  cd conda_environments/
 1610  conda env list
 1611  mkdir gpt-2
 1612  conda activate gpt-2
 1613  ls
 1614  cd gpt-2/
 1615  conda list > condalist_log.txt
 1616  cat condalist_log.txt 
 1617  pip freeze
 1618  pip freeze > pipfreeze_log.txt
 1619  ls
 1620  cd ..
 1621  git status
 1622  git add conda_environments/gpt-2/
 1623  git commit -m "Log GPT-2 environment"
 1624  git push
 1625  ls
 1626  conda enc list
 1627  conda env list
 1628  git status
 1629  ls reproducibility/
 1630  git rm -r reproducibility/tgen/
 1631  git rm -r /reproducibility/tgen/
 1632  git rm -r reproducibility/tgen
 1633  git rm -r ~/nlg-ra/reproducibility/tgen
 1634  git rm -r ~/nlg-ra/reproducibility/tgen/
 1635  ls reproducibility/
 1636  conda env list
 1637  conda activate data2text_plan_py
 1638  cd nlg-ra/reproducibility/test_data2text-plan-py/data2text-plan-py/
 1639  ll
 1640  ls
 1641  ls rotowire/
 1642  ls
 1643  ls rotowire
 1644  ls drive_rotowire/test/
 1645  ls
 1646  ls rotowire/
 1647  ls
 1648  ls rotowire/
 1649  ls
 1650  ls rotowire
 1651  ls drive_rotowire/
 1652  ls drive_rotowire/test/
 1653  ls
 1654  ls rotowire/
 1655  ls drive_rotowire/
 1656  ls
 1657  ls drive_rotowire/
 1658  ls
 1659  ls rotowire_original_dataset/
 1660  ls
 1661  ls rotowire_original_dataset/
 1662  ls rotowire/
 1663  ls drive_rotowire/
 1664  ls
 1665  cd nlg-ra/
 1666  git status
 1667  git add reproducibility/data2text-plan-py/bayer_dataset/Imitation\ of\ create_datasets\ script.ipynb
 1668  git status
 1669  git commit -m "Added code to create train-roto-ptrs.txt file"
 1670  git push
 1671  git status
 1672  git add reproducibility/test_data2text-plan-py/data2text-plan-py/Exploring\ Data\ for\ data2text.ipynb 
 1673  git commit -m "Go into details of train-roto-ptrs.txt file"
 1674  git push
 1675  git status
 1676  conda env list
 1677  conda activate data2text_plan_py
 1678  ls
 1679  cd nlg-ra/reproducibility/data2text-plan-py/
 1680  ll
 1681  ls
 1682  ls boxscore-data/
 1683  ls bayer_dataset/
 1684  ls bayer_dataset/inter/
 1685  ls
 1686  cd bayer_dataset/
 1687  ls
 1688  ll
 1689  ls
 1690  ls ~/nlg-ra/
 1691  ls ~
 1692  ls ~/tmp/
 1693  mv src_train.txt ~/tmp/
 1694  ls
 1695  mv tgt_train.txt ~/tmp/
 1696  ls
 1697  mv train_content_plan.txt ~/tmp/
 1698  ls
 1699  mkdir test
 1700  ls inter/
 1701  mv inter/train_content_plan.txt ~/tmp/
 1702  ls ~/tmp/
 1703  mv ~/tmp/train_content_plan.txt ~/tmp/train_content_plan_INTER.txt 
 1704  ls ~/tmp
 1705  ls
 1706  ls inter/
 1707  ls test/
 1708  ls
 1709  ls rotowire/
 1710  ls
 1711  ls rotowire/
 1712  ls rotowire/inter/
 1713  ls 
 1714  ls test/
 1715  ls
 1716  ls inter/
 1717  ls test/
 1718  ls
 1719  mkdir preprocess
 1720  ls
 1721  BASE = ~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset
 1722  IDENTIFIER=cc
 1723  ls
 1724  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1725  cd ..
 1726  ls
 1727  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1728  echo $BASE
 1729  BASE = ~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/
 1730  BASE=~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/
 1731  echo $BASE
 1732  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1733  BASE=~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset
 1734  echo $BASE
 1735  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1736  ls
 1737  ls boxscore-data/
 1738  ls bayer_dataset/
 1739  ll
 1740  ls
 1741  ls bayer_dataset/
 1742  ls bayer_dataset/rotowire/
 1743  ls
 1744  ls boxscore-data/
 1745  ls boxscore-data/rotowire/
 1746  ls
 1747  ls bayer_dataset/
 1748  ls bayer_dataset/rotowire/
 1749  ls boxscore-data/rotowire/
 1750  ls
 1751  cp ~/nlg-ra/reproducibility/test_data2text-plan-py/data2text-plan-py/rotowire_original_dataset/train.json bayer_dataset/rotowire/
 1752  ls bayer_dataset/
 1753  ls bayer_dataset/rotowire/
 1754  ls
 1755  ls boxscore-data/rotowire/
 1756  ls boxscore-data/rotowire/inter/
 1757  ls boxscore-data/rotowire/test/
 1758  ls boxscore-data/rotowire/inter/
 1759  ls
 1760  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1761  rmdir boxscore-data/preprocess/
 1762  ls boxscore-data/
 1763  rm -r boxscore-data/preprocess/
 1764  ls boxscore-data/
 1765  BASE=~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data
 1766  IDENTIFIER=cc
 1767  mkdir boxscore-data/preprocess
 1768  ls boxscore-data/
 1769  python preprocess.py -train_src1 $BASE/rotowire/src_train.txt -train_tgt1 $BASE/rotowire/train_content_plan.txt -train_src2 $BASE/rotowire/inter/train_content_plan.txt -train_tgt2 $BASE/rotowire/tgt_train.txt -valid_src1 $BASE/rotowire/src_valid.txt -valid_tgt1 $BASE/rotowire/valid_content_plan.txt -valid_src2 $BASE/rotowire/inter/valid_content_plan.txt -valid_tgt2 $BASE/rotowire/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/rotowire/train-roto-ptrs.txt
 1770  ls
 1771  ls bayer_dataset/
 1772  ls bayer_dataset/inter/
 1773  ls bayer_dataset/
 1774  ls
 1775  echo $BASE
 1776  ls
 1777  ls boxscore-data/
 1778  ls boxscore-data/preprocess/
 1779  rm boxscore-data/preprocess/roto.train.1.pt
 1780  rm boxscore-data/preprocess/roto.valid.1.pt
 1781  rm boxscore-data/preprocess/roto.vocab.pt
 1782  ls boxscore-data/preprocess/
 1783  echo $BASE
 1784  echo $IDENTIFIER 
 1785  ls boxscore-data/rotowire/
 1786  python preprocess.py -train_src1 $BASE/rotowire/src_train.txt -train_tgt1 $BASE/rotowire/train_content_plan.txt -train_src2 $BASE/rotowire/inter/train_content_plan.txt -train_tgt2 $BASE/rotowire/tgt_train.txt -valid_src1 $BASE/rotowire/src_valid.txt -valid_tgt1 $BASE/rotowire/valid_content_plan.txt -valid_src2 $BASE/rotowire/inter/valid_content_plan.txt -valid_tgt2 $BASE/rotowire/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/rotowire/train-roto-ptrs.txt
 1787  ls
 1788  ls bayer_dataset/
 1789  ls bayer_dataset/preprocess/
 1790  echo $BASE
 1791  BASE=~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset
 1792  echo $BASE
 1793  ls bayer_dataset/
 1794  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1795  ls bayer_dataset/preprocess/
 1796  echo "Now try training the model"
 1797  ls bayer_dataset/
 1798  mkdir bayer_dataset/gen_model
 1799  ls bayer_dataset/
 1800  ls boxscore-data/gen_model/cc/
 1801  mkdir bayer_dataset/gen_model/cc
 1802  ls bayer_dataset/gen_model/
 1803  ls bayer_dataset/gen_model/cc/
 1804  echo $BASE
 1805  echo $GPUID
 1806  GPUID=0
 1807  echo $GPUID
 1808  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 10 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1809  ls boxscore-data/rotowire/
 1810  ls
 1811  ls boxscore-data/gen_model/
 1812  ls boxscore-data/
 1813  ls boxscore-data/transform_gen/
 1814  conda activate data2text_plan_py
 1815  cd nlg-ra/reproducibility/test_data2text-plan-py/data2text-plan-py/
 1816  ls
 1817  ls
 1818  ls tryouts/
 1819  rm -r tryouts/
 1820  ls
 1821  ls tmp/
 1822  mkdir backups
 1823  ls
 1824  mv ~/nlg-ra/reproducibility/data2text-plan-py/data_2_text_leaflets_v1.zip ~/tmp/
 1825  ls tmp/
 1826  cd nlg-ra/
 1827  git status
 1828  git checkout reproducibility/data2text-plan-py/bayer_dataset/Imitation\ of\ create_datasets\ script.ipynb
 1829  git status
 1830  git mv reproducibility/data2text-plan-py/bayer_dataset/Imitation\ of\ create_datasets\ script.ipynb reproducibility/data2text-plan-py/bayer_dataset/Imitating_create_datasets_sources.ipynb
 1831  git status
 1832  git commit -m "Rename the file"
 1833  git push
 1834  git status
 1835  git checkout -- reproducibility/data2text-plan-py/bayer_dataset/Imitating_create_datasets_sources.ipynb
 1836  git status
 1837  git add reproducibility/data2text-plan-py/bayer_dataset/Imitate_create_datasets_script_final.ipynb
 1838  git commit -m "Notebook for creating same output files of create_dataset.py script in faster way"
 1839  git push
 1840  ls ~
 1841  cd ~
 1842  ls tmp/
 1843  cd nlg-ra/reproducibility/data2text-plan-py/
 1844  ls
 1845  conda env list
 1846  conda activate data2text_plan_py
 1847  ls
 1848  ls bayer_dataset/
 1849  ls
 1850  zip -r data_2_text_leaflets_v1.zip bayer_dataset/
 1851  ls
 1852  ls bayer_dataset/
 1853  rm bayer_dataset/src_train.txt bayer_dataset/src_valid.txt bayer_dataset/tgt_train.txt bayer_dataset/tgt_valid.txt bayer_dataset/train-roto-ptrs.txt bayer_dataset/train_content_plan.txt bayer_dataset/valid_content_plan.txt
 1854  ls bayer_dataset/
 1855  rm bayer_dataset/test/src_test.txt bayer_dataset/test/tgt_test.txt
 1856  rm bayer_dataset/inter/train_content_plan.txt bayer_dataset/inter/valid_content_plan.txt 
 1857  ls
 1858  ls bayer_dataset/
 1859  ls bayer_dataset/test/
 1860  ls bayer_dataset/inter/
 1861  ls
 1862  ls bayer_dataset/
 1863  rm bayer_dataset/preprocess/roto.train.1.pt bayer_dataset/preprocess/roto.valid.1.pt bayer_dataset/preprocess/roto.vocab.pt
 1864  ls bayer_dataset/preprocess/
 1865  ls bayer_dataset/
 1866  ls bayer_dataset/gen_model/
 1867  ls bayer_dataset/gen_model/cc/
 1868  ls bayer_dataset/inter/
 1869  ls bayer_dataset/test/
 1870  ls 
 1871  cp bayer_dataset/Imitating_create_datasets_sources.ipynb bayer_dataset/Imitate_create_datasets_script_final.ipynb
 1872  ls bayer_dataset/
 1873  ls bayer_dataset/rotowire/
 1874  ls
 1875  ls bayer_dataset/
 1876  rm bayer_dataset/src_train.txt bayer_dataset/tgt_train.txt bayer_dataset/inter/train_content_plan.txt 
 1877  ls bayer_dataset/
 1878  ls bayer_dataset/inter/
 1879  ls bayer_dataset/
 1880  ls
 1881  ls bayer_dataset/
 1882  ls bayer_dataset/inter/
 1883  ls bayer_dataset/test/
 1884  ls bayer_dataset/
 1885  echo "02.02 - Running preprocess script"
 1886  # BASE=~/boxscore-data
 1887  BASE=~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset
 1888  IDENTIFIER=cc
 1889  ls bayer_dataset/preprocess/
 1890  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1891  echo "Try training with new input"
 1892  GPUID=0
 1893  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 25 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1894  conda env list
 1895  conda list
 1896  conda list | grep 'torch'
 1897  conda list
 1898  ls
 1899  ls baz
 1900  ls bayer_dataset/
 1901  zip -r data_2_text_leaflets_v2 bayer_dataset/
 1902  ls 
 1903  mv data_2_text_leaflets_v2.zip ~/tmp/
 1904  ls ~/tmp/
 1905  ls
 1906  cd bayer_dataset/
 1907  ls
 1908  rm src_train.txt src_valid.txt tgt_train.txt tgt_valid.txt train_content_plan.txt valid_content_plan.txt 
 1909  ls 
 1910  rm train-roto-ptrs.txt
 1911  ls 
 1912  rm inter/train_content_plan.txt inter/valid_content_plan.txt 
 1913  rm test/src_test.txt test/tgt_test.txt 
 1914  ls 
 1915  ls inter/
 1916  ls test/
 1917  ls
 1918  ls preprocess/
 1919  rm preprocess/roto.train.1.pt preprocess/roto.valid.1.pt preprocess/roto.vocab.pt
 1920  ls preprocess/
 1921  ls
 1922  ls preprocess/
 1923  ls inter/
 1924  ls test/
 1925  echo $BASE
 1926  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1927  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 25 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1928  python preprocess.py -train_src1 $BASE/src_train.txt -train_tgt1 $BASE/train_content_plan.txt -train_src2 $BASE/inter/train_content_plan.txt -train_tgt2 $BASE/tgt_train.txt -valid_src1 $BASE/src_valid.txt -valid_tgt1 $BASE/valid_content_plan.txt -valid_src2 $BASE/inter/valid_content_plan.txt -valid_tgt2 $BASE/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/train-roto-ptrs.txt
 1929  ls bayer_dataset/
 1930  echo $BASE
 1931  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 25 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1932  conda activate data2text_plan_py
 1933  cd nlg-ra/reproducibility/test_data2text-plan-py/data2text-plan-py/
 1934  ls
 1935  cd nlg-ra/
 1936  git status
 1937  git add reproducibility/data2text-plan-py/Data_Exploration.ipynb 
 1938  git commit -m "Go into details of train.py script"
 1939  git mv reproducibility/data2text-plan-py/Data_Exploration.ipynb reproducibility/data2text-plan-py/Data_Exploration_Leaflets.ipynb 
 1940  git status
 1941  git commit -m "Rename file since it is used only on Leaflets dataset"
 1942  git push
 1943  git status
 1944  git status\
 1945  git status
 1946  git add reproducibility/data2text-plan-py/Data_Exploration_NBA.ipynb
 1947  git commit -m "Notebook to inverstigate NBA dataset"
 1948  git push
 1949  conda env list
 1950  conda activate data2text_plan_py
 1951  cd reproducibility/data2text-plan-py/
 1952  ls
 1953  echo $BASE
 1954  BASE=~/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset
 1955  IDENTIFIER=cc
 1956  ls bayer_dataset/preprocess/
 1957  ls bayer_dataset/
 1958  GPUID=0
 1959  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 2 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1960  echo $BASE
 1961  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 2 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1962  conda env list
 1963  conda activate data2text_plan_py
 1964  cd nlg-ra/reproducibility/data2text-plan-py/
 1965  ls
 1966  ls bayer_dataset/preprocess/
 1967  ls bayer_dataset/
 1968  echo $BASE
 1969  ls 
 1970  ls bayer_dataset/
 1971  conda env list
 1972  pip install --user ipykernel
 1973  python -m ipykernel install --user --name=data2text_plan_py
 1974  pwd
 1975  ls
 1976  ls bayer_dataset/
 1977  ls bayer_dataset/preprocess/
 1978  ls 
 1979  ls boxscore-data/
 1980  ls boxscore-data/rotowire/
 1981  ls boxscore-data/preprocess/
 1982  echo "Run preprocess on NBA dataset, but firstly delete what I have in preprocess"
 1983  rm boxscore-data/preprocess/roto.train.1.pt boxscore-data/preprocess/roto.valid.1.pt boxscore-data/preprocess/roto.vocab.pt
 1984  ls boxscore-data/preprocess/
 1985  BASE=~/nlg-ra/reproducibility/data2text-plan-py/boxscore-data
 1986  python preprocess.py -train_src1 $BASE/rotowire/src_train.txt -train_tgt1 $BASE/rotowire/train_content_plan.txt -train_src2 $BASE/rotowire/inter/train_content_plan.txt -train_tgt2 $BASE/rotowire/tgt_train.txt -valid_src1 $BASE/rotowire/src_valid.txt -valid_tgt1 $BASE/rotowire/valid_content_plan.txt -valid_src2 $BASE/rotowire/inter/valid_content_plan.txt -valid_tgt2 $BASE/rotowire/tgt_valid.txt -save_data $BASE/preprocess/roto -src_seq_length 1000 -tgt_seq_length 1000 -dynamic_dict -train_ptr $BASE/rotowire/train-roto-ptrs.txt
 1987  ls 
 1988  ls boxscore-data/
 1989  ls boxscore-data/rotowire/
 1990  ls boxscore-data/preprocess/
 1991  GPUID=0
 1992  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/delet -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 2 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1993  echo "Better message"
 1994  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/delet -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 2 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1995  echo "Better message"
 1996  python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/delet -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 2 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5
 1997  ls
 1998  cd nlg-ra/
 1999  ls
 2000  git clone https://github.com/huggingface/transformers
 2001  ls
 2002  cd transformers/
 2003  conda env list
 2004  history | grep "conda create"
 2005  history | grep "conda creat"
 2006  history | grep "conda"
 2007  conda env list
 2008  cd ..
 2009  ls
 2010  touch t5_env.yaml
 2011  ls
 2012  conda env create -f t5_env.yml
 2013  conda activate t5_text2text
 2014  conda list | grep "python"
 2015  conda list | grep "pytorch"
 2016  cd transformers/
 2017  ls
 2018  pip install -e .
 2019  conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch
 2020  pip install gitpython
 2021  pip install rouge-score
 2022  pip install sacrebleu
 2023  ls
 2024  mkdir t5_finetuning
 2025  ls
 2026  cd t5_finetuning/
 2027  ls
 2028  cd .. 
 2029  mv t5_finetuning t5_finetuning_input
 2030  ls
 2031  ls t5_finetuning_input/
 2032  mkdir t5_finetuning_output
 2033  ls
 2034  rmdir t5_finetuning_input/
 2035  rmdir t5_finetuning_output/
 2036  ls
 2037  mkdir t5_finetuning
 2038  cd t5_finetuning/
 2039  mkdir input_data
 2040  mkdir outputs
 2041  ls
 2042  ls input_data/
 2043  rm -r input_data/
 2044  ls
 2045  mkdir input_data
 2046  ls
 2047  ls input_data/
 2048  cat input_data/test.source | head -n 1
 2049  ls input_data/
 2050  cd input_data/
 2051  pwd
 2052  export DATA_DIR="/home/ruslan_yermakov/nlg-ra/transformers/t5_finetuning/input_data"
 2053  echo $DATA_DIR 
 2054  cd ..
 2055  cd outputs/
 2056  pwd
 2057  export DATA_DIR_OUT="/home/ruslan_yermakov/nlg-ra/transformers/t5_finetuning/outputs"
 2058  echo $DATA_DIR_OUT
 2059  cd ..
 2060  ls
 2061  python finetune_trainer.py --model_name_or_path t5-base 
 2062  --data_dir $DATA_DIR --output_dir $DATA_DIR_OUT 
 2063  --n_train -1 
 2064  --n_val 500 
 2065  --max_target_length=60 
 2066  --val_max_target_length=100 
 2067  --test_max_target_length=100 
 2068  --eval_steps 2000 
 2069  --save_steps 2000 
 2070  --num_train_epochs 1 
 2071  --do_train 
 2072  --do_eval 
 2073  --predict_with_generate 
 2074  --per_device_train_batch_size 32 
 2075  --per_device_eval_batch_size 64 
 2076  --overwrite_output_dir 
 2077  --learning_rate=1e-4 
 2078  python finetune_trainer.py --help
 2079  ls
 2080  cd examples/seq2seq/
 2081  ls
 2082  python finetune_trainer.py --help
 2083  python finetune_trainer.py --t5-base --data_dir $DATA_DIR --output_dir $DATA_DIR_OUT --n_train -1 --n_val 500 --max_target_length=60 --val_max_target_length=100 --test_max_target_length=100 --eval_steps 2000 --save_steps 2000 --num_train_epochs 1 --do_train --do_eval --predict_with_generate --per_device_train_batch_size 32 --per_device_eval_batch_size 64 --overwrite_output_dir --learning_rate=1e-4 --gradient_accumulation_steps 2
 2084  python finetune_trainer.py --model_name_or_path t5-base --data_dir $DATA_DIR --output_dir $DATA_DIR_OUT --n_train -1 --n_val 500 --max_target_length=60 --val_max_target_length=100 --test_max_target_length=100 --eval_steps 2000 --save_steps 2000 --num_train_epochs 1 --do_train --do_eval --predict_with_generate --per_device_train_batch_size 32 --per_device_eval_batch_size 64 --overwrite_output_dir --learning_rate=1e-4 --gradient_accumulation_steps 2
 2085  echo "redice batch size"
 2086  git status
 2087  cd ../../..
 2088  git status
 2089  git add transformers/
 2090  git status
 2091  git commit -m "Clone transformers from Hugging Face"
 2092  git add Data_t5_finetuning.ipynb
 2093  git commit -m "Notebook to prepare input data for fine-tuning T5"
 2094  git add t5_env.yml 
 2095  git status
 2096  git reset HEAD t5_env.yml
 2097  ls
 2098  mv t5_env.yml conda_environments/t5_env.yml
 2099  ls conda_environments/
 2100  git status
 2101  git add conda_environments/t5_env.yml
 2102  git commit -m "Angelo's conda env for t5_finetuning"
 2103  git push
 2104  git status
 2105  history > commands_t5_finetuning.txt
