{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose BART model from checkpoints based on ROUGE-2 score.    \n",
    "\n",
    "Find out which **beam_search** worked the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# use metrics from HF\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'bertscore',\n",
       " 'bleu',\n",
       " 'bleurt',\n",
       " 'comet',\n",
       " 'coval',\n",
       " 'f1',\n",
       " 'gleu',\n",
       " 'glue',\n",
       " 'indic_glue',\n",
       " 'meteor',\n",
       " 'precision',\n",
       " 'recall',\n",
       " 'rouge',\n",
       " 'sacrebleu',\n",
       " 'sari',\n",
       " 'seqeval',\n",
       " 'squad',\n",
       " 'squad_v2',\n",
       " 'super_glue',\n",
       " 'wer',\n",
       " 'xnli']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list availbale metrics\n",
    "\n",
    "from datasets import list_metrics\n",
    "metrics_list = list_metrics()\n",
    "\n",
    "metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rouge metric\n",
    "metric = datasets.load_metric('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 77.7778, 'rouge2': 62.5, 'rougeL': 77.7778, 'rougeLsum': 77.7778}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "test1 = ['this is test and I believe it works']\n",
    "test2 = ['this is test and I hope it works well enough']\n",
    "\n",
    "metric.add_batch(predictions=test1, references=test2)\n",
    "\n",
    "# computer the rouge score\n",
    "res = metric.compute()\n",
    "\n",
    "{k: round(v.mid.fmeasure * 100, 4) for k, v in res.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED):\n",
    "    \"\"\"\n",
    "    PATH_ORIGINAL - target test generations\n",
    "    PATH_GENERATED - path to the generated sections\n",
    "    \"\"\"\n",
    "    \n",
    "    # read references\n",
    "    with open(PATH_ORIGINAL) as f:\n",
    "        gold_references = [line.strip() for line in f]\n",
    "    \n",
    "    # read candidates\n",
    "    with open(PATH_GENERATED) as f:\n",
    "        current_candidates = [line.strip() for line in f]\n",
    "\n",
    "    # check same length\n",
    "    assert len(current_candidates) == len(gold_references)\n",
    "\n",
    "    ### calculate ROUGE scores\n",
    "\n",
    "    # add pairs of predictions/reference to a temporary and memory efficient cache table (HF)\n",
    "    metric.add_batch(predictions=current_candidates, references=gold_references)\n",
    "\n",
    "    # length of a Metric object will return the number of examples (predictions or predictions/references pair)\n",
    "    assert len(metric) == len(current_candidates)\n",
    "\n",
    "    # gathers all the cached predictions and references to compute the metric score\n",
    "    final_score = metric.compute()\n",
    "\n",
    "    # logging\n",
    "    # print(PATH_GENERATED, \" ~~~ \", {k: round(v.mid.fmeasure * 100, 4) for k, v in final_score.items()})\n",
    "\n",
    "    final_rouge_scores = {k: round(v.mid.fmeasure * 100, 4) for k, v in final_score.items()}\n",
    "\n",
    "    # get only the rouge2\n",
    "    rouge2 = final_rouge_scores['rouge2']\n",
    "    \n",
    "    return {PATH_GENERATED: (rouge2, final_rouge_scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ORIGINAL = '/home/ruslan_yermakov/nlg-ra/T5_experiments/T5_plain/input_data/test.target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep results of different bart models(checkpints) and beam_size\n",
    "bart_all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_1.txt': (33.5639, {'rouge1': 45.2693, 'rouge2': 33.5639, 'rougeL': 39.4679, 'rougeLsum': 39.4814})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_10.txt': (30.9003, {'rouge1': 43.437, 'rouge2': 30.9003, 'rougeL': 36.0984, 'rougeLsum': 36.1253})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_5.txt': (31.9611, {'rouge1': 44.2596, 'rouge2': 31.9611, 'rougeL': 37.2803, 'rougeLsum': 37.2782})}\n"
     ]
    }
   ],
   "source": [
    "# BART outputs final\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_1.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_10.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_5.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUGE-score results when running ./run_eval:    \n",
    "\n",
    "\"Beam_size 1\": {\"rouge1\": 45.9848, \"rouge2\": 34.1539, \"rougeL\": 39.9457, \"rougeLsum\": 45.1163, \"n_obs\": 742, \"runtime\": 95, \"seconds_per_sample\": 0.128}   \n",
    "\n",
    "\"Beam_size 10\": {\"rouge1\": 44.0955, \"rouge2\": 31.2756, \"rougeL\": 36.4828, \"rougeLsum\": 43.0052, \"n_obs\": 742, \"runtime\": 569, \"seconds_per_sample\": 0.7668}   \n",
    "\n",
    "\"Beam_size 5\": {\"rouge1\": 44.8606, \"rouge2\": 32.4029, \"rougeL\": 37.6062, \"rougeLsum\": 43.8227, \"n_obs\": 742, \"runtime\": 285, \"seconds_per_sample\": 0.3841}    \n",
    "\n",
    "\n",
    "**Note**: Results a bit different...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-1000/test_generations_beam_1.txt': (30.4052, {'rouge1': 43.5828, 'rouge2': 30.4052, 'rougeL': 36.7879, 'rougeLsum': 36.7659})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-1000/test_generations_beam_10.txt': (29.1274, {'rouge1': 42.5189, 'rouge2': 29.1274, 'rougeL': 34.776, 'rougeLsum': 34.7649})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-1000/test_generations_beam_5.txt': (29.38, {'rouge1': 42.8437, 'rouge2': 29.38, 'rougeL': 35.1359, 'rougeLsum': 35.1595})}\n"
     ]
    }
   ],
   "source": [
    "# BART outputs - checkpoint 1000\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-1000/test_generations_beam_1.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-1000/test_generations_beam_10.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-1000/test_generations_beam_5.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUGE-score results when running ./run_eval:      \n",
    "\n",
    "\"Beam_size 1\": {\"rouge1\": 44.3901, \"rouge2\": 31.0958, \"rougeL\": 37.3945, \"rougeLsum\": 43.3649, \"n_obs\": 742, \"runtime\": 91, \"seconds_per_sample\": 0.1226}       \n",
    "\n",
    "\"Beam_size 10\": {\"rouge1\": 43.2283, \"rouge2\": 29.5757, \"rougeL\": 35.1969, \"rougeLsum\": 42.0986, \"n_obs\": 742, \"runtime\": 559, \"seconds_per_sample\": 0.7534}      \n",
    "\n",
    "\"Beam_size 5\": {\"rouge1\": 43.5783, \"rouge2\": 29.8195, \"rougeL\": 35.6655, \"rougeLsum\": 42.4785, \"n_obs\": 742, \"runtime\": 282, \"seconds_per_sample\": 0.3801}       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-2000/test_generations_beam_1.txt': (32.3359, {'rouge1': 44.6612, 'rouge2': 32.3359, 'rougeL': 38.5314, 'rougeLsum': 38.5622})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-2000/test_generations_beam_10.txt': (30.1754, {'rouge1': 42.9894, 'rouge2': 30.1754, 'rougeL': 35.6597, 'rougeLsum': 35.6787})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-2000/test_generations_beam_5.txt': (30.7662, {'rouge1': 43.5571, 'rouge2': 30.7662, 'rougeL': 36.3665, 'rougeLsum': 36.3722})}\n"
     ]
    }
   ],
   "source": [
    "# BART outputs - checkpoint 2000\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-2000/test_generations_beam_1.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-2000/test_generations_beam_10.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-2000/test_generations_beam_5.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-3000/test_generations_beam_1.txt': (33.1498, {'rouge1': 45.0864, 'rouge2': 33.1498, 'rougeL': 39.1962, 'rougeLsum': 39.2036})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-3000/test_generations_beam_10.txt': (30.7035, {'rouge1': 43.42, 'rouge2': 30.7035, 'rougeL': 36.0595, 'rougeLsum': 36.078})}\n",
      "{'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-3000/test_generations_beam_5.txt': (31.4999, {'rouge1': 43.8639, 'rouge2': 31.4999, 'rougeL': 36.8585, 'rougeLsum': 36.8544})}\n"
     ]
    }
   ],
   "source": [
    "# BART outputs - checkpoint 3000\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-3000/test_generations_beam_1.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-3000/test_generations_beam_10.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)\n",
    "\n",
    "\n",
    "PATH_GENERATED = '/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/checkpoint-3000/test_generations_beam_5.txt'\n",
    "\n",
    "res = calc_rouge_bart(PATH_ORIGINAL, PATH_GENERATED)\n",
    "print(res)\n",
    "\n",
    "bart_all_results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best-performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bart_all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sorting_fun_rouge1(result):\n",
    "    for key in result:\n",
    "        return result[key][1]['rouge1']\n",
    "\n",
    "def _sorting_fun_rouge2(result):\n",
    "    for key in result:\n",
    "        return result[key][1]['rouge2']\n",
    "    \n",
    "def _sorting_fun_rougeL(result):\n",
    "    for key in result:\n",
    "        return result[key][1]['rougeL']\n",
    "\n",
    "def _sorting_fun_rougeLsum(result):\n",
    "    for key in result:\n",
    "        return result[key][1]['rougeLsum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best generated text according to ROUGE1:  {'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_1.txt': (33.5639, {'rouge1': 45.2693, 'rouge2': 33.5639, 'rougeL': 39.4679, 'rougeLsum': 39.4814})}\n"
     ]
    }
   ],
   "source": [
    "print('Best generated text according to ROUGE-1: ', sorted(bart_all_results, key=_sorting_fun_rouge1, reverse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best generated text according to ROUGE2:  {'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_1.txt': (33.5639, {'rouge1': 45.2693, 'rouge2': 33.5639, 'rougeL': 39.4679, 'rougeLsum': 39.4814})}\n"
     ]
    }
   ],
   "source": [
    "print('Best generated text according to ROUGE-2: ', sorted(bart_all_results, key=_sorting_fun_rouge2, reverse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best generated text according to ROUGE-L:  {'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_1.txt': (33.5639, {'rouge1': 45.2693, 'rouge2': 33.5639, 'rougeL': 39.4679, 'rougeLsum': 39.4814})}\n"
     ]
    }
   ],
   "source": [
    "print('Best generated text according to ROUGE-L: ', sorted(bart_all_results, key=_sorting_fun_rougeL, reverse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best generated text according to ROUGE-Lsum:  {'/home/ruslan_yermakov/nlg-ra/T5_experiments/BART_base/test_generations_beam_1.txt': (33.5639, {'rouge1': 45.2693, 'rouge2': 33.5639, 'rougeL': 39.4679, 'rougeLsum': 39.4814})}\n"
     ]
    }
   ],
   "source": [
    "print('Best generated text according to ROUGE-Lsum: ', sorted(bart_all_results, key=_sorting_fun_rougeLsum, reverse=True)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5_text2text",
   "language": "python",
   "name": "t5_text2text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
