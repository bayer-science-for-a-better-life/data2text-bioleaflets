{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boxscore-data/gen_model/roto_stage2_cc-beam5_gens.txt') as reader:\n",
    "    generated_NBA_text = reader.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_NBA_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Toronto Raptors ( 11 ) defeated the Philadelphia 76ers ( 4 - 14 ) 122 - 95 on Friday night . In a battle between two of the best defenses in the NBA , the Spurs were able to pull away in the second half , out - scoring the 76ers 31 - 17 in the first half . The Grizzlies shot a respectable 48 percent from the field , while shooting a respectable 48 percent from the field . Kyle Lowry led the way with 24 points on 7 - of - 9 shooting , while 6 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line . 4 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line . 4 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line , while 4 - of - 6 from the free throw line . 4 - of - 6 from the free throw line , as he finished with a game - high 13 points , while also adding seven rebounds , three assists , two steals and one block , in 40 minutes . Toronto , on the other hand , have now lost five of its last three games , and have now lost five of its last six games , with the loss to the Trail Blazers on Friday . The team shot a respectable 48 percent from the field , but could n't get it going , as they shot just 38 percent from the field , but still managed to get it going , as they shot just 38 percent from the field , while shooting just 48 percent from the field . DeMar DeRozan led the team with 24 points , while shooting just 4 - of - 13 from the field . DeMar DeRozan was the only other starter to score in double figures , as he finished with 14 points on 4 - of - 13 shooting , along with 0 - of - 9 from behind the arc . The only other player to score in double digits for the Nets was 1 - of - 6 from behind the arc . 1 - of - 6 shooting from behind the arc , as he finished with a game - high 5 points , along with four rebounds , three assists , and a steal , in 38 minutes . Robert Saric was solid in his return to the court , scoring 20 points on 7 - of - 11 shooting , along with 6 - of - 9 from the free throw line . The only other player to score in double digits for the Nets was 1 - of - 9 from long range . 1 - of - 6 from the free throw line , along with five rebounds , three assists , two steals and one block , in 40 minutes . Dario Saric was the only other starter to score in double figures , finishing with 20 points on 7 - of - 11 shooting , along with 6 - of - 9 from the free throw line . The only other player to score in double digits for the Nets was 1 - of - 9 from behind the arc . 1 - of - 6 from the free throw line , along with five rebounds , three assists , and a steal , in 32 minutes . Robert Saric was the only other starter to score in double figures , as he finished with 20 points on 7 - of - 11 shooting , along with 6 - of - 9 from the free throw line . The only other player to score in double digits for the Nets was 1 - of - 9 from behind the arc . 1 - of - 6 from the free throw line , along with five rebounds , three assists , two steals and one block , in 40 minutes . Dario Saric was the only other starter to score in double figures , finishing with 20 points on 7 - of - 11 shooting , along with 6 - of - 9 from the free throw line . The Trail Blazers ' next game will be on the road against the Dallas Mavericks on Friday , while the Spurs will travel to San Antonio Wednesday to play the Spurs .\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_NBA_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boxscore-data/rotowire/inf_tgt_valid.txt') as reader:\n",
    "    original_NBA_text = reader.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_NBA_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Toronto Raptors ( 29 - 15 ) recorded their eighth consecutive win Sunday with a 112 - 94 victory against the visiting Los Angeles Clippers ( 28 - 16 ) . Seven Raptors scored in double figures , led by Kyle Lowry 's 21 points , as Toronto moved to within one game of matching its franchise - long winning streak set in 2001 - 2 . Jonas Valanciunas added 20 and DeMar DeRozan had 18 points . Terrence Ross matched the latter with 18 off the bench as Toronto 's resevers came up big . Corey Joseph had 12 points while Patrick Patterson and Bismack Biyombo both scored 10 . Ross was 5 of 7 from three - point range to pace the reserves , who outscored the Clippers ' bench , 51 - 29 . The Raptors , who also took two games this season from the Lakers , swept the season season series from the Clippers , marking the first time in franchise history they have swept both Los Angeles teams in a season . Chris Paul totaled 23 points and 11 assists to lead the Clippers , who jumped to a 13 - point first - quarter advantage before faltering . DeAndre Jordan finished with 15 points and 13 rebounds while JJ Redick added 17 points . The Clippers ' bench , though , could n't match Toronto 's as the resevers were held to 39 percent shooting from the field , including 2 of 10 from three - point range .\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_NBA_text[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The LA Clippers ( 20 ) defeated the Toronto Raptors ( 29 - 15 ) 94 - 112 on Friday . The Clippers came into this game as a five - game losing streak with the win , but it was n't enough to pull away in the first half . In fact , there were only two ties and two lead changes , with no team leading by more than 12 points . The Clippers were led by Chris Paul , who scored 23 points on 9 - of - 17 shooting , while 3 - of - 7 from the free throw line . 2 - of - 7 shooting from the free throw line , with 2 - of - 7 from the free throw line . 2 - of - 7 shooting from the free throw line , while 2 - of - 7 from the free throw line . 2 - of - 7 shooting from the free throw line , with 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , while 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , while 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , while 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , while 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , while 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , with 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , however , as 2 - of - 7 from the free throw line . 2 - of - 7 from the free throw line , but it was n't enough to get the job done . 2 - of - 3 from the free throw line , however , as 2 - of - 3 from the free throw line . 2 - of - 7 from the free throw line , but it was n't enough to get the job done in the game . 2 - of - 3 shooting , 2 - of - 5 from three - point range , with 2 - of - 3 from three - point range . 2 - of - 3 shooting from the free throw line , where he finished with a game - high 13 points , while also adding seven rebounds , three assists , a steal and a block . DeMar DeRozan was the only other starter to score in double figures , as he finished with 18 points on 6 - of - 17 shooting , including 2 - of - 2 from three - point range . 4 - of - 2 from the free throw line , but it was n't enough to get it going , as he shot just 6 - of - 20 from the field . The only other player to score in double digits for the Spurs was 4 - of - 4 from the free throw line . 4 - of - 6 from the free throw line , but it was n't enough to get it going , as they shot just 38 percent from the field . Up next , the Grizzlies will travel to San Antonio Wednesday to take on the Spurs , while the Spurs will travel to San Antonio Wednesday to play the Spurs .\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_NBA_text[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produced files after running preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**:  \n",
    "-train_src1 /rotowire/src_train.txt   \n",
    "-train_tgt1 /rotowire/train_content_plan.txt   \n",
    "-train_src2 /rotowire/inter/train_content_plan.txt   \n",
    "-train_tgt2 /rotowire/tgt_train.txt   \n",
    "\n",
    "-valid_src1 /rotowire/src_valid.txt   \n",
    "-valid_tgt1 /rotowire/valid_content_plan.txt   \n",
    "-valid_src2 /rotowire/inter/valid_content_plan.txt   \n",
    "-valid_tgt2 /rotowire/tgt_valid.txt   \n",
    "\n",
    "\n",
    "**Output**:  \n",
    "\n",
    "\n",
    "/preprocess/roto.train.1.pt      \n",
    "/preprocess/roto.valid.1.pt      \n",
    "/preprocess/roto.vocab.pt         # vocabulary  \n",
    "\n",
    "/rotowire/train-roto-ptrs.txt  \n",
    "\n",
    "\n",
    "Loading train dataset from /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/preprocess/roto.train.1.pt, number of examples: 3371  \n",
    "\n",
    "Loading valid dataset from /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/boxscore-data/preprocess/roto.valid.1.pt, number of examples: 722  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boxscore-data/rotowire/train-roto-ptrs.txt') as reader:\n",
    "    # This reads the remaining lines from the file object and returns them as a list.\n",
    "    train_roto_ptrs = reader.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not understand the purpose of this file, as it appears it is never used in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3371"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_roto_ptrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,0 2,1 4,2 6,3 11,4 13,7 17,5 18,6 20,8 22,9 74,10 75,11 77,12 81,13 102,15 109,11 115,17 116,18 127,19 142,24 182,26 192,27 210,28 211,29 213,30 216,31 219,32 220,33 233,35 245,39\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_roto_ptrs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-776831c61474>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-776831c61474>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    -input_path $BASE/rotowire/train.json -train_content_plan $BASE/rotowire/inter/train_content_plan.txt\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-input_path $BASE/rotowire/train.json -train_content_plan $BASE/rotowire/inter/train_content_plan.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boxscore-data/rotowire/train-roto-ptrs.txt') as reader:\n",
    "    train_roto_ptrs = reader.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script what is going on LEAFLETS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of **preprocess**  \n",
    "\n",
    " * number of source features- stage 1: 3.    \n",
    " * number of target features- stage 1: 0.  \n",
    " * number of source features- stage 2: 3.   \n",
    " * number of target features- stage 2: 0.  \n",
    "Building `Fields` object...   \n",
    "Building & saving training data...  \n",
    "('average src size', 26, 1000)   \n",
    " * saving train data shard to /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/preprocess/roto.train.1.pt.   \n",
    "Building & saving vocabulary...   \n",
    " * reloading /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/preprocess/roto.train.1.pt.   \n",
    " * tgt1 vocab size: 105.   \n",
    " * tgt2 vocab size: 7382.   \n",
    " * src1 vocab size: 4660.    \n",
    " * src1_feat_0 vocab size: 3.   \n",
    " * src1_feat_1 vocab size: 22.   \n",
    " * src1_feat_2 vocab size: 4.   \n",
    " * src2 vocab size: 4658.   \n",
    " * src2_feat_0 vocab size: 3.   \n",
    " * src2_feat_1 vocab size: 22.   \n",
    " * src2_feat_2 vocab size: 4.   \n",
    "Building & saving validation data...  \n",
    "('average src size', 25, 120)   \n",
    " * saving valid data shard to /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/preprocess/roto.valid.1.pt.    \n",
    "(data2text_plan_py) ruslan_yermakov@ip-10-123-133-120:~/nlg-ra/reproducibility/data2text-plan-py$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "\n",
    "import onmt\n",
    "import onmt.io\n",
    "import onmt.Models\n",
    "import onmt.ModelConstructor\n",
    "import onmt.modules\n",
    "from onmt.Utils import use_gpu\n",
    "import opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 25 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Command\"   \n",
    "\n",
    "\"python train.py -data $BASE/preprocess/roto -save_model $BASE/gen_model/$IDENTIFIER/roto -encoder_type1 mean -decoder_type1 pointer -enc_layers1 1 -dec_layers1 1 -encoder_type2 brnn -decoder_type2 rnn -enc_layers2 2 -dec_layers2 2 -batch_size 5 -feat_merge mlp -feat_vec_size 600 -word_vec_size 600 -rnn_size 600 -seed 1234 -start_checkpoint_at 4 -epochs 25 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -report_every 100 -copy_attn -truncated_decoder 100 -gpuid $GPUID -attn_hidden 64 -reuse_copy_attn -start_decay_at 4 -learning_rate_decay 0.97 -valid_batch_size 5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE='/home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset'\n",
    "\n",
    "TRAIN_DATASET='/home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/preprocess/roto.train.1.pt'\n",
    "\n",
    "VOCAB_FILE='/home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/preprocess/roto.vocab.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazily_load_dataset(corpus_type):\n",
    "    \"\"\"\n",
    "    Dataset generator. Don't do extra stuff here, like printing,\n",
    "    because they will be postponed to the first loading time.\n",
    "\n",
    "    Args:\n",
    "        corpus_type: 'train' or 'valid'\n",
    "    Returns:\n",
    "        A list of dataset, the dataset(s) are lazily loaded.\n",
    "    \"\"\"\n",
    "    assert corpus_type in [\"train\", \"valid\"]\n",
    "\n",
    "    def lazy_dataset_loader(pt_file, corpus_type):\n",
    "        dataset = torch.load(pt_file)\n",
    "        print('Loading %s dataset from %s, number of examples: %d' %\n",
    "              (corpus_type, pt_file, len(dataset)))\n",
    "        return dataset\n",
    "    \n",
    "    yield lazy_dataset_loader(TRAIN_DATASET, corpus_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset from /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/preprocess/roto.train.1.pt, number of examples: 1000\n"
     ]
    }
   ],
   "source": [
    "# Peek the fisrt dataset to determine the data_type.\n",
    "# (All datasets have the same data_type).\n",
    "\n",
    "first_dataset = next(lazily_load_dataset(\"train\"))\n",
    "data_type = first_dataset.data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<onmt.io.TextDataset.TextDataset at 0x7fc4db8f5290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src1_feat_0',\n",
       " 'src1_feat_1',\n",
       " 'src1_feat_2',\n",
       " 'ptrs',\n",
       " 'src2',\n",
       " 'src1',\n",
       " 'src_map',\n",
       " 'tgt1_planning',\n",
       " 'indices',\n",
       " 'tgt2',\n",
       " 'tgt1',\n",
       " 'src2_feat_1',\n",
       " 'src2_feat_0',\n",
       " 'alignment',\n",
       " 'src2_feat_2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dataset.examples[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into how 1st sample from roto.train.1.pt looks like - LEAFLETS\n",
    "first_dataset.examples[0].__dict__['src2_feat_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication',\n",
       " u'Indication')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dataset.examples[0].__dict__['src2_feat_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fields(dataset, data_type, checkpoint=None):\n",
    "    \n",
    "    fields = onmt.io.load_fields_from_vocab(torch.load(VOCAB_FILE), data_type)\n",
    "    \n",
    "    fields = dict([(k, f) for (k, f) in fields.items()\n",
    "                   if k in dataset.examples[0].__dict__])\n",
    "\n",
    "    if data_type == 'text' or data_type == 'box':\n",
    "        print(' * vocabulary size. source1 = %d; target1 = %d, source2 = %d; target2 = %d' %\n",
    "              (len(fields['src1'].vocab), len(fields['tgt1'].vocab), len(fields['src2'].vocab), len(fields['tgt2'].vocab)))\n",
    "\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * vocabulary size. source1 = 4660; target1 = 105, source2 = 4658; target2 = 7382\n"
     ]
    }
   ],
   "source": [
    "# Load fields generated from preprocess phase.\n",
    "fields = load_fields(first_dataset, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alignment': <torchtext.data.field.Field at 0x7fc4d9c83850>,\n",
       " 'indices': <torchtext.data.field.Field at 0x7fc4d9c838d0>,\n",
       " 'ptrs': <torchtext.data.field.Field at 0x7fc4d9c83890>,\n",
       " 'src1': <onmt.io.BoxField.BoxField at 0x7fc53434a110>,\n",
       " 'src1_feat_0': <onmt.io.BoxField.BoxField at 0x7fc4d9c835d0>,\n",
       " 'src1_feat_1': <onmt.io.BoxField.BoxField at 0x7fc4d9c83610>,\n",
       " 'src1_feat_2': <onmt.io.BoxField.BoxField at 0x7fc4d9c83650>,\n",
       " 'src2': <torchtext.data.field.Field at 0x7fc4d9c836d0>,\n",
       " 'src2_feat_0': <torchtext.data.field.Field at 0x7fc4d9c83750>,\n",
       " 'src2_feat_1': <torchtext.data.field.Field at 0x7fc4d9c83790>,\n",
       " 'src2_feat_2': <torchtext.data.field.Field at 0x7fc4d9c837d0>,\n",
       " 'src_map': <torchtext.data.field.Field at 0x7fc4d9c83810>,\n",
       " 'tgt1': <torchtext.data.field.Field at 0x7fc4d9c83690>,\n",
       " 'tgt1_planning': <onmt.io.BoxField.BoxField at 0x7fc4d9c83590>,\n",
       " 'tgt2': <torchtext.data.field.Field at 0x7fc4d9c83710>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bayer_dataset/train_content_plan.txt') as reader:\n",
    "    # This reads the remaining lines from the file object and returns them as a list.\n",
    "    leaflets_pointerplan_train = reader.readlines()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19 12 35 18 12 75 12 53 26 13 47 60 15 58 29 64 43 16 16 26 6 25 32 22 8 21 4 25 37 60 15 56 13 23 25 67 14 69 13 30 38 11 77 47 63 29 17 13 23 25 41 29 73 5 29 65 48 9 29 45 26 9 69 15 60 62 54 20 40 23 26 9 29 10 29 44 46 7\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaflets_pointerplan_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'19',\n",
       " u'12',\n",
       " u'35',\n",
       " u'18',\n",
       " u'12',\n",
       " u'75',\n",
       " u'12',\n",
       " u'53',\n",
       " u'26',\n",
       " u'13',\n",
       " u'47',\n",
       " u'60',\n",
       " u'15',\n",
       " u'58',\n",
       " u'29',\n",
       " u'64',\n",
       " u'43',\n",
       " u'16',\n",
       " u'16',\n",
       " u'26',\n",
       " u'6',\n",
       " u'25',\n",
       " u'32',\n",
       " u'22',\n",
       " u'8',\n",
       " u'21',\n",
       " u'4',\n",
       " u'25',\n",
       " u'37',\n",
       " u'60',\n",
       " u'15',\n",
       " u'56',\n",
       " u'13',\n",
       " u'23',\n",
       " u'25',\n",
       " u'67',\n",
       " u'14',\n",
       " u'69',\n",
       " u'13',\n",
       " u'30',\n",
       " u'38',\n",
       " u'11',\n",
       " u'77',\n",
       " u'47',\n",
       " u'63',\n",
       " u'29',\n",
       " u'17',\n",
       " u'13',\n",
       " u'23',\n",
       " u'25',\n",
       " u'41',\n",
       " u'29',\n",
       " u'73',\n",
       " u'5',\n",
       " u'29',\n",
       " u'65',\n",
       " u'48',\n",
       " u'9',\n",
       " u'29',\n",
       " u'45',\n",
       " u'26',\n",
       " u'9',\n",
       " u'69',\n",
       " u'15',\n",
       " u'60',\n",
       " u'62',\n",
       " u'54',\n",
       " u'20',\n",
       " u'40',\n",
       " u'23',\n",
       " u'26',\n",
       " u'9',\n",
       " u'29',\n",
       " u'10',\n",
       " u'29',\n",
       " u'44',\n",
       " u'46',\n",
       " u'7')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dataset.examples[0].__dict__['tgt1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * src feature 0 size = 3\n",
      " * src feature 1 size = 22\n",
      " * src feature 2 size = 4\n"
     ]
    }
   ],
   "source": [
    "def collect_report_features(fields):\n",
    "    src_features = onmt.io.collect_features(fields, side='src1')\n",
    "    tgt_features = onmt.io.collect_features(fields, side='tgt1')\n",
    "\n",
    "    for j, feat in enumerate(src_features):\n",
    "        print(' * src feature %d size = %d' % (j, len(fields[feat].vocab)))\n",
    "    for j, feat in enumerate(tgt_features):\n",
    "        print(' * tgt feature %d size = %d' % (j, len(fields[feat].vocab)))\n",
    "\n",
    "# Report src/tgt features.\n",
    "collect_report_features(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alignment': <torchtext.data.field.Field at 0x7fc4d9c83850>,\n",
       " 'indices': <torchtext.data.field.Field at 0x7fc4d9c838d0>,\n",
       " 'ptrs': <torchtext.data.field.Field at 0x7fc4d9c83890>,\n",
       " 'src1': <onmt.io.BoxField.BoxField at 0x7fc53434a110>,\n",
       " 'src1_feat_0': <onmt.io.BoxField.BoxField at 0x7fc4d9c835d0>,\n",
       " 'src1_feat_1': <onmt.io.BoxField.BoxField at 0x7fc4d9c83610>,\n",
       " 'src1_feat_2': <onmt.io.BoxField.BoxField at 0x7fc4d9c83650>,\n",
       " 'src2': <torchtext.data.field.Field at 0x7fc4d9c836d0>,\n",
       " 'src2_feat_0': <torchtext.data.field.Field at 0x7fc4d9c83750>,\n",
       " 'src2_feat_1': <torchtext.data.field.Field at 0x7fc4d9c83790>,\n",
       " 'src2_feat_2': <torchtext.data.field.Field at 0x7fc4d9c837d0>,\n",
       " 'src_map': <torchtext.data.field.Field at 0x7fc4d9c83810>,\n",
       " 'tgt1': <torchtext.data.field.Field at 0x7fc4d9c83690>,\n",
       " 'tgt1_planning': <onmt.io.BoxField.BoxField at 0x7fc4d9c83590>,\n",
       " 'tgt2': <torchtext.data.field.Field at 0x7fc4d9c83710>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'<blank>',\n",
       " u'<blank>',\n",
       " u'<blank>',\n",
       " u'<blank>',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'AWAY',\n",
       " u'HOME',\n",
       " u'HOME',\n",
       " u'HOME')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dataset.examples[0].__dict__['src1_feat_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model.\n",
    "model1, model2 = build_model(model_opt, opt, fields, checkpoint)\n",
    "tally_parameters(model1)\n",
    "tally_parameters(model2)\n",
    "check_save_model_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading train dataset from /home/ruslan_yermakov/nlg-ra/reproducibility/data2text-plan-py/bayer_dataset/preprocess/roto.train.1.pt, number of examples: 1000\n",
    " * vocabulary size. source1 = 4660; target1 = 105, source2 = 4658; target2 = 7382\n",
    " * src feature 0 size = 3\n",
    " * src feature 1 size = 22\n",
    " * src feature 2 size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2text_plan_py",
   "language": "python",
   "name": "data2text_plan_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
